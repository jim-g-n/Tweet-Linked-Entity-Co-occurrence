{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dc7dfdd",
   "metadata": {},
   "source": [
    "# FEL Graph Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e148eb3c",
   "metadata": {},
   "source": [
    "This notebook creates the graph-tool graph and data files from processed FEL annotations. Annotations are in a CSV file with each line representing a different tweet. A first list shows the linked entities, while a second list the corresponding confidence in each entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba18008-e320-4036-b178-ad3cdf941197",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_tool import Graph\n",
    "import graph_tool.all as gt\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from itertools import zip_longest\n",
    "import ast\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24855465-8f3b-4d15-a5ba-53b77200cd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fel_df = pd.read_csv('fel_entities_all_processed_plus_conf.zip', compression = 'bz2')\n",
    "fel_df.entity_names = fel_df.apply(lambda x: ast.literal_eval(x['entity_names']), axis = 1)\n",
    "fel_df.ed_conf = fel_df.apply(lambda x: ast.literal_eval(x['ed_conf']), axis = 1)\n",
    "fel_df.ed_conf = fel_df['ed_conf'].apply(lambda x : pd.to_numeric(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88efb54a-9a72-4299-b147-15499ddecb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_entities(entity_array):\n",
    "    entity_count = dict()\n",
    "\n",
    "    for entity_list in entity_array:\n",
    "        entities = []\n",
    "\n",
    "        for entity_name in entity_list:\n",
    "\n",
    "            if entity_name not in entities:\n",
    "                entities.append(entity_name)\n",
    "                if entity_name in entity_count:\n",
    "                    entity_count[entity_name] += 1\n",
    "                else:\n",
    "                    entity_count[entity_name] = 1\n",
    "\n",
    "    return entity_count\n",
    "\n",
    "def count_entity_pairs(entity_array, entity_int_mapping):\n",
    "    entity_pairs_counts = dict()\n",
    "\n",
    "    for entity_list in entity_array:\n",
    "        entities = []\n",
    "        for entity_name in set(entity_list):\n",
    "            \n",
    "            if (entity_name not in entities):\n",
    "                entities.append(entity_name)\n",
    "        \n",
    "        # counts are tracked for how often keywords occur together\n",
    "        for entity_pair in list(combinations(entities, 2)):\n",
    "            entity_0 = entity_int_mapping[entity_pair[0]]\n",
    "            entity_1 = entity_int_mapping[entity_pair[1]]\n",
    "            if frozenset((entity_0, entity_1)) in entity_pairs_counts:\n",
    "                entity_pairs_counts[frozenset((entity_0, entity_1))] += 1\n",
    "            else:\n",
    "                entity_pairs_counts[frozenset((entity_0, entity_1))] = 1      \n",
    "    return entity_pairs_counts\n",
    "\n",
    "def create_graph(entity_array):\n",
    "    entity_count = collect_entities(entity_array)\n",
    "    entity_int_mapping = dict(zip(list(entity_count.keys()),[i for i in range(len(entity_count))]))\n",
    "    entity_pairs = count_entity_pairs(entity_array, entity_int_mapping)\n",
    "\n",
    "    num_nodes = len(entity_count)\n",
    "    g = Graph(directed=False)\n",
    "    vlist = g.add_vertex(n=num_nodes)\n",
    "    g.add_edge_list([tuple(list(x) + [y]) for x,y in entity_pairs.items()], eprops=[('weight','int')])\n",
    "\n",
    "    return g, entity_count, entity_int_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dae8229-49bb-42c0-bd4f-908a6bc0ba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conn_comp(g, entity_int_mapping):\n",
    "    con_g = gt.extract_largest_component(g, prune = False)\n",
    "    vertex_arr = con_g.get_vertices()\n",
    "\n",
    "    org_reverse_entity_mapping = dict((v,k) for k,v in entity_int_mapping.items())\n",
    "    reverse_entity_mapping = {i:org_reverse_entity_mapping[i] for i in vertex_arr}\n",
    "    reverse_entity_mapping = dict(zip([i for i in range(len(vertex_arr))], [org_reverse_entity_mapping[i] for i in vertex_arr]))\n",
    "    \n",
    "    con_g = gt.extract_largest_component(g, prune = True)\n",
    "\n",
    "    return con_g, reverse_entity_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b1dabe-b5fa-4c38-8073-c0786f79e453",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_graphs_dict = dict()\n",
    "\n",
    "for conf in [-3,-2.75,-2.5,-2.25,-2,-1.75,-1.5,-1.25,-1]:\n",
    "    entity_array = []\n",
    "    for i in range(len(fel_df)):\n",
    "        entity_array.append(np.array(fel_df.entity_names[i])[np.where(np.array(fel_df.ed_conf[i])>conf)[0]])\n",
    "    full_graphs_dict[str(conf)] = create_graph(entity_array)\n",
    "    print(str(conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f65fc1e-c3c7-43e3-bcee-7cfc909863b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_list = ['-3','-2.75','-2.5','-2.25','-2','-1.75','-1.5','-1.25','-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbfa25e-e8ce-40c8-8e29-b1b9a7c0987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for conf in conf_list:\n",
    "    full_graphs_dict[conf][0].save(\"fel_all_full_conf_\" + conf[1:] + \".gt.gz\")\n",
    "    \n",
    "    with open('fel_all_full_conf_' + conf[1:] + '_data.pickle', 'wb') as handle:\n",
    "        pickle.dump(full_graphs_dict[conf][1:], handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5749135-925c-4032-b15c-fc9cdb41bdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_graphs_dict = dict()\n",
    "\n",
    "for conf in conf_list:\n",
    "    conn_graphs_dict[conf] = get_conn_comp(full_graphs_dict[conf][0], full_graphs_dict[conf][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04533bb9-1b22-43fd-94e1-ac5c1d3b148c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for conf in conf_list:\n",
    "    conn_graphs_dict[conf][0].save(\"fel_all_conn_conf_\" + conf[1:] + \".gt.gz\")\n",
    "    \n",
    "    with open('fel_all_conn_conf_' + conf[1:] + '_data.pickle', 'wb') as handle:\n",
    "        pickle.dump(conn_graphs_dict[conf][1:], handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
